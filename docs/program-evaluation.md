# Program Evaluation & Learning

## Summary
A lightweight evaluation framework for measuring program effectiveness, capturing lessons, and translating findings into decision-ready updates.

## Evaluation goals
- Confirm outcomes align with program intent and funder expectations.
- Identify which delivery choices drive scholar success.
- Provide evidence for iteration priorities and resourcing.
- Surface risks early (equity gaps, drop-off points, partner drift).

## Core questions
- Who is the program reaching, and who is missing?
- Which scholar milestones matter most for success?
- What delivery moments create the biggest lift?
- Where do scholars experience friction or drop-off?
- How do partners perceive value, and what do they need next?

## Measurement stack
- Outcomes: completion, retention, persistence, and next-step achievements.
- Experience: satisfaction, trust, belonging, and support quality.
- Equity: distribution across demographics and opportunity access.
- Operations: cycle time, responsiveness, and quality checks.
- Partner impact: engagement, referral activity, and renewal intent.

## Data sources
- Scholar surveys and pulse checks (pre, mid, post).
- Program operations logs and case notes.
- Application and review data.
- Partner interviews and feedback forms.
- Alumni check-ins and referral data.

## Evaluation cadence
- Launch baseline: define targets, cohorts, and comparison points.
- Mid-cycle review: track early signals and adjust delivery.
- End-of-cycle: summarize outcomes, gaps, and recommendations.
- Quarterly synthesis: compare cohorts and document shifts.

## Insights workflow
- Intake: log hypotheses and questions at kickoff.
- Analysis: mix quantitative trends with qualitative narratives.
- Validation: review findings with program and CX leads.
- Actioning: assign owners for priority changes.
- Storytelling: capture concise summaries for leadership.

## Reporting outputs
- Evaluation brief (1 page with 3-5 findings).
- Learning backlog with priority ranking.
- Evidence map linked to program design decisions.
- Impact dashboard updates in the Impact Vault.

## Roles & ownership
- Program lead: owns evaluation plan and decisions.
- Data/insights: runs analysis and maintains evidence map.
- CX lead: interprets scholar voice and support signals.
- Partnerships: validates partner-facing outcomes.

## Readiness checklist
- Baseline metrics defined and shared.
- Data sources mapped with owners.
- Survey instruments reviewed and approved.
- Analysis timeline aligned with program calendar.
- Reporting format agreed with leadership.
